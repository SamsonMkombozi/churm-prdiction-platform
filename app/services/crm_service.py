"""
FIXED CRM Service with Correct Table Names
crm_service_correct_tables.py

Updated to use your actual PostgreSQL table names:
- crm_customers (not customers)
- nav_mpesa_transactions (not payments)
- crm_tickets (not tickets)  
- spl_statistics (already correct)
"""

import psycopg2
import psycopg2.extras
from datetime import datetime, timedelta
from flask import current_app
from app.extensions import db
from app.models.customer import Customer
from app.models.payment import Payment
from app.models.ticket import Ticket
from app.models.usage_stats import UsageStats
from app.models.company import Company
from app.repositories.customer_repository import CustomerRepository
from app.repositories.payment_repository import PaymentRepository
from app.repositories.ticket_repository import TicketRepository
from app.repositories.usage_repository import UsageRepository
import traceback
import time
import logging

logger = logging.getLogger(__name__)

class EnhancedCRMService:
    """Enhanced CRM Service with CORRECT table names for your PostgreSQL database"""
    
    def __init__(self, company):
        self.company = company
        self.connection = None
        
        logger.info(f"üîç Initializing CRM Service for: {company.name} (ID: {company.id})")
        
        # Initialize repositories
        self.customer_repo = CustomerRepository(company)
        self.payment_repo = PaymentRepository(company)
        self.ticket_repo = TicketRepository(company)
        self.usage_repo = UsageRepository(company)
        
        # Performance tracking
        self.sync_stats = {
            'start_time': None,
            'customers': {'new': 0, 'updated': 0, 'skipped': 0, 'errors': 0},
            'payments': {'new': 0, 'updated': 0, 'skipped': 0, 'errors': 0},
            'tickets': {'new': 0, 'updated': 0, 'skipped': 0, 'errors': 0},
            'usage': {'new': 0, 'updated': 0, 'skipped': 0, 'errors': 0},
            'connection_method': 'unknown',
            'total_records': 0,
            'sync_duration': 0,
            'records_per_second': 0
        }
    
    def get_connection_info(self):
        """Get connection info using encrypted database schema"""
        
        logger.info(f"üîç === CONNECTION INFO DEBUG for {self.company.name} ===")
        
        try:
            postgresql_configured = self.company.has_postgresql_config()
            api_configured = self.company.has_api_config()
            
            pg_config = self.company.get_postgresql_config()
            api_config = self.company.get_api_config()
            
            logger.info(f"üìä PostgreSQL Configuration:")
            logger.info(f"   Host: {repr(pg_config['host'])}")
            logger.info(f"   Port: {repr(pg_config['port'])}")
            logger.info(f"   Database: {repr(pg_config['database'])}")
            logger.info(f"   Username: {repr(pg_config['username'])}")
            logger.info(f"   Password: {'***' if pg_config['password'] else 'None'}")
            
            logger.info(f"üåê API Configuration:")
            logger.info(f"   Base URL: {repr(api_config['base_url'])}")
            
            if postgresql_configured:
                preferred_method = 'postgresql'
                logger.info("‚úÖ PostgreSQL configuration FOUND and VALID!")
            elif api_configured:
                preferred_method = 'api'
                logger.info("‚úÖ API configuration FOUND and VALID!")
            else:
                preferred_method = 'none'
                logger.warning("‚ùå NO valid configuration found!")
            
            connection_info = {
                'postgresql_configured': postgresql_configured,
                'api_configured': api_configured,
                'preferred_method': preferred_method,
                'performance_boost': '10-50x faster' if postgresql_configured else 'Standard speed',
                'connection_details': {
                    'postgresql': {
                        'host': pg_config['host'],
                        'port': pg_config['port'],
                        'database': pg_config['database'],
                        'username': pg_config['username'],
                        'status': 'configured' if postgresql_configured else 'incomplete'
                    } if pg_config['host'] else {},
                    'api': {
                        'base_url': api_config['base_url'],
                        'status': 'configured' if api_configured else 'incomplete'
                    } if api_config['base_url'] else {}
                }
            }
            
            logger.info(f"üéØ FINAL RESULT: {preferred_method}")
            logger.info(f"=== END CONNECTION INFO DEBUG ===")
            
            return connection_info
            
        except Exception as e:
            logger.error(f"‚ùå Error getting connection info: {e}")
            logger.error(traceback.format_exc())
            
            return {
                'postgresql_configured': False,
                'api_configured': False,
                'preferred_method': 'none',
                'performance_boost': 'Configuration error',
                'connection_details': {},
                'error': str(e)
            }
    
    def test_postgresql_connection(self):
        """Test PostgreSQL connection with correct table names"""
        
        logger.info(f"üß™ Testing PostgreSQL connection for {self.company.name}")
        
        try:
            pg_config = self.company.get_postgresql_config()
            
            logger.info(f"üîó Connection parameters:")
            logger.info(f"   Host: {pg_config['host']}")
            logger.info(f"   Port: {pg_config['port']}")
            logger.info(f"   Database: {pg_config['database']}")
            logger.info(f"   Username: {pg_config['username']}")
            
            if not all([pg_config['host'], pg_config['database'], pg_config['username'], pg_config['password']]):
                return {
                    'success': False,
                    'message': 'PostgreSQL configuration incomplete',
                    'details': ['Some required fields are missing']
                }
            
            conn_params = {
                'host': pg_config['host'],
                'port': int(pg_config['port']),
                'dbname': pg_config['database'],
                'user': pg_config['username'],
                'password': pg_config['password']
            }
            
            # Test actual connection with correct table names
            with psycopg2.connect(**conn_params) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT version()")
                    version = cursor.fetchone()[0]
                    
                    # ‚úÖ Check for YOUR ACTUAL CRM tables
                    cursor.execute("""
                        SELECT table_name 
                        FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name IN ('crm_customers', 'nav_mpesa_transactions', 'crm_tickets', 'spl_statistics')
                        ORDER BY table_name
                    """)
                    tables = [row[0] for row in cursor.fetchall()]
                    
                    # Get sample data counts from YOUR tables
                    table_counts = {}
                    for table in tables:
                        try:
                            cursor.execute(f"SELECT COUNT(*) FROM {table}")
                            table_counts[table] = cursor.fetchone()[0]
                        except Exception as e:
                            table_counts[table] = f"Error: {str(e)}"
                    
                    logger.info(f"‚úÖ PostgreSQL connection SUCCESS!")
                    logger.info(f"üìä Version: {version}")
                    logger.info(f"üìä Your CRM Tables: {tables}")
                    logger.info(f"üìä Table Counts: {table_counts}")
                    
                    return {
                        'success': True,
                        'message': '‚úÖ PostgreSQL connection successful with your CRM tables!',
                        'details': [
                            f'Connected to: {conn_params["host"]}:{conn_params["port"]}/{conn_params["dbname"]}',
                            f'PostgreSQL version: {version.split()[0]} {version.split()[1]}',
                            f'CRM tables found: {len(tables)} tables',
                            f'Data records available: {sum(count for count in table_counts.values() if isinstance(count, int)):,}'
                        ],
                        'tables': tables,
                        'table_counts': table_counts
                    }
                    
        except ImportError:
            return {
                'success': False,
                'message': 'psycopg2 module not installed',
                'details': ['Run: pip install psycopg2-binary']
            }
        except psycopg2.OperationalError as e:
            logger.error(f"‚ùå PostgreSQL connection FAILED: {e}")
            return {
                'success': False,
                'message': f'PostgreSQL connection failed: {str(e)}',
                'details': [
                    'Common causes:',
                    '‚Ä¢ Incorrect host or port',
                    '‚Ä¢ Wrong database name', 
                    '‚Ä¢ Invalid username/password',
                    '‚Ä¢ Network connectivity issues',
                    '‚Ä¢ PostgreSQL server not running'
                ]
            }
        except Exception as e:
            logger.error(f"‚ùå Unexpected error: {e}")
            return {
                'success': False,
                'message': f'Connection test failed: {str(e)}',
                'details': ['Check your PostgreSQL configuration']
            }
    
    def _get_postgresql_connection(self):
        """Get PostgreSQL connection using encrypted credentials"""
        
        if self.connection and not self.connection.closed:
            return self.connection
        
        try:
            pg_config = self.company.get_postgresql_config()
            
            conn_params = {
                'host': pg_config['host'],
                'port': int(pg_config['port']),
                'dbname': pg_config['database'],
                'user': pg_config['username'],
                'password': pg_config['password']
            }
            
            logger.info(f"üîó Connecting to: {conn_params['user']}@{conn_params['host']}:{conn_params['port']}/{conn_params['dbname']}")
            
            self.connection = psycopg2.connect(**conn_params)
            self.connection.autocommit = True
            
            logger.info("‚úÖ PostgreSQL connection established!")
            return self.connection
            
        except Exception as e:
            logger.error(f"‚ùå PostgreSQL connection failed: {str(e)}")
            raise
    
    def sync_data_selective(self, sync_options=None):
        """Enhanced selective sync with correct table names"""
        
        if sync_options is None:
            sync_options = {
                'sync_customers': True,
                'sync_payments': True,
                'sync_tickets': True,
                'sync_usage': False
            }
        
        self.sync_stats['start_time'] = time.time()
        
        logger.info(f"üöÄ === STARTING SYNC for {self.company.name} ===")
        logger.info(f"üìä Sync options: {sync_options}")
        
        connection_info = self.get_connection_info()
        self.sync_stats['connection_method'] = connection_info['preferred_method']
        
        try:
            self.company.mark_sync_started()
            
            if connection_info['preferred_method'] == 'postgresql':
                logger.info("üöÄ Using PostgreSQL direct connection (FAST) with correct table names")
                return self._sync_via_postgresql(sync_options)
            elif connection_info['preferred_method'] == 'api':
                logger.info("üåê Using API connection (Standard)")
                return self._sync_via_api(sync_options)
            else:
                error_msg = (
                    "‚ùå No sync method configured!\n\n"
                    f"Debug info:\n"
                    f"‚Ä¢ PostgreSQL configured: {connection_info['postgresql_configured']}\n"
                    f"‚Ä¢ API configured: {connection_info['api_configured']}\n"
                    f"‚Ä¢ Company: {self.company.name} (ID: {self.company.id})"
                )
                logger.error(error_msg)
                raise Exception(error_msg)
                
        except Exception as e:
            error_msg = f"Enhanced sync failed: {str(e)}"
            logger.error(error_msg)
            logger.error(traceback.format_exc())
            
            self.company.mark_sync_failed(error_msg)
            
            return {
                'success': False,
                'message': error_msg,
                'stats': self.sync_stats,
                'error_details': str(e),
                'debug_info': {
                    'company_id': self.company.id,
                    'company_name': self.company.name,
                    'connection_info': connection_info
                }
            }
    
    def _sync_via_postgresql(self, sync_options):
        """Sync via PostgreSQL with CORRECT table names"""
        
        logger.info("üöÄ === PostgreSQL Sync Started with CORRECT Table Names ===")
        
        try:
            conn = self._get_postgresql_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
            
            logger.info("‚úÖ PostgreSQL connection established for sync")
            
            # Sync customers from crm_customers (not customers)
            if sync_options.get('sync_customers', True):
                logger.info("üë• Syncing customers from crm_customers table...")
                self._sync_customers_postgresql(cursor)
            
            # Sync payments from nav_mpesa_transactions (not payments)
            if sync_options.get('sync_payments', True):
                logger.info("üí∞ Syncing payments from nav_mpesa_transactions table...")
                self._sync_payments_postgresql(cursor)
            
            # Sync tickets from crm_tickets (not tickets)
            if sync_options.get('sync_tickets', True):
                logger.info("üé´ Syncing tickets from crm_tickets table...")
                self._sync_tickets_postgresql(cursor)
            
            # Sync usage from spl_statistics (correct)
            if sync_options.get('sync_usage', False):
                logger.info("üìä Syncing usage from spl_statistics table...")
                self._sync_usage_postgresql(cursor)
            
            # Calculate performance
            elapsed_time = time.time() - self.sync_stats['start_time']
            total_records = sum(
                self.sync_stats[key]['new'] + self.sync_stats[key]['updated'] 
                for key in ['customers', 'payments', 'tickets', 'usage']
            )
            
            self.sync_stats.update({
                'sync_duration': round(elapsed_time, 2),
                'total_records': total_records,
                'records_per_second': round(total_records / elapsed_time, 2) if elapsed_time > 0 else 0
            })
            
            db.session.commit()
            self.company.mark_sync_completed()
            
            logger.info(f"‚úÖ === PostgreSQL Sync Completed with Correct Tables ===")
            logger.info(f"üìä {total_records:,} records in {elapsed_time:.1f}s")
            logger.info(f"‚ö° {self.sync_stats['records_per_second']} records/sec")
            
            return {
                'success': True,
                'message': f'‚úÖ PostgreSQL sync completed! Processed {total_records:,} records using correct table names',
                'stats': self.sync_stats,
                'performance': {
                    'connection_method': 'postgresql',
                    'sync_duration': self.sync_stats['sync_duration'],
                    'total_records_processed': total_records,
                    'records_per_second': self.sync_stats['records_per_second']
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå PostgreSQL sync failed: {str(e)}")
            logger.error(traceback.format_exc())
            
            db.session.rollback()
            self.company.mark_sync_failed(str(e))
            
            raise Exception(f"PostgreSQL sync failed: {str(e)}")
        
        finally:
            if self.connection:
                self.connection.close()
                self.connection = None
    
    def _sync_customers_postgresql(self, cursor):
        """‚úÖ Sync customers from crm_customers table (CORRECT TABLE NAME)"""
        try:
            # ‚úÖ Query YOUR ACTUAL crm_customers table
            cursor.execute("""
                SELECT 
                    id, customer_name, email, phone, mobile, address, location,
                    status, connection_status, account_type, monthly_charges, 
                    total_charges, outstanding_balance, service_type, connection_type,
                    package, bandwidth_plan, signup_date, date_installed, 
                    created_at, updated_at
                FROM crm_customers
                ORDER BY id
                LIMIT 5000
            """)
            
            customers_data = cursor.fetchall()
            logger.info(f"üìä Retrieved {len(customers_data):,} customers from crm_customers table")
            
            # Process in batches
            batch_size = 500
            for i in range(0, len(customers_data), batch_size):
                batch = customers_data[i:i + batch_size]
                
                for customer_row in batch:
                    try:
                        customer_data = dict(customer_row)
                        created = self.customer_repo.create_or_update(customer_data)
                        
                        if created:
                            self.sync_stats['customers']['new'] += 1
                        else:
                            self.sync_stats['customers']['updated'] += 1
                            
                    except Exception as e:
                        logger.error(f"‚ùå Customer error {customer_row.get('id', '?')}: {e}")
                        self.sync_stats['customers']['errors'] += 1
                        continue
                
                db.session.commit()
                logger.info(f"‚úÖ Customer batch {i//batch_size + 1} done")
            
            logger.info(f"‚úÖ Customers sync completed: {self.sync_stats['customers']}")
            
        except Exception as e:
            logger.error(f"‚ùå Customer sync failed: {e}")
            raise
    
    def _sync_payments_postgresql(self, cursor):
        """‚úÖ Sync payments from nav_mpesa_transactions table (CORRECT TABLE NAME)"""
        try:
            # ‚úÖ Query YOUR ACTUAL nav_mpesa_transactions table
            cursor.execute("""
                SELECT 
                    "TransID" as id, 
                    "TransAmount" as tx_amount, 
                    "BillRefNumber" as account_no,
                    "MSISDN" as phone_no, 
                    "FirstName" as payer, 
                    "TransTime" as created_at,
                    "TransTime" as transaction_time, 
                    "TransID" as mpesa_reference,
                    TRUE as posted_to_ledgers,
                    FALSE as is_refund,
                    'completed' as status
                FROM nav_mpesa_transactions
                WHERE "TransTime"::date >= CURRENT_DATE - INTERVAL '90 days'
                ORDER BY "TransTime" DESC
                LIMIT 10000
            """)
            
            payments_data = cursor.fetchall()
            logger.info(f"üí∞ Retrieved {len(payments_data):,} payments from nav_mpesa_transactions table")
            
            # Process in batches
            batch_size = 500
            for i in range(0, len(payments_data), batch_size):
                batch = payments_data[i:i + batch_size]
                
                for payment_row in batch:
                    try:
                        payment_data = dict(payment_row)
                        result = self.payment_repo.create_or_update(payment_data)
                        
                        if result is True:
                            self.sync_stats['payments']['new'] += 1
                        elif result is False:
                            self.sync_stats['payments']['updated'] += 1
                        else:
                            self.sync_stats['payments']['skipped'] += 1
                            
                    except Exception as e:
                        logger.error(f"‚ùå Payment error {payment_row.get('id', '?')}: {e}")
                        self.sync_stats['payments']['errors'] += 1
                        continue
                
                db.session.commit()
                logger.info(f"üí∞ Payment batch {i//batch_size + 1} done")
            
            logger.info(f"‚úÖ Payments sync completed: {self.sync_stats['payments']}")
            
        except Exception as e:
            logger.error(f"‚ùå Payment sync failed: {e}")
            raise
    
    def _sync_tickets_postgresql(self, cursor):
        """‚úÖ Sync tickets from crm_tickets table (CORRECT TABLE NAME)"""
        try:
            # ‚úÖ Query YOUR ACTUAL crm_tickets table
            cursor.execute("""
                SELECT 
                    id, customer_no, subject, message, category_id, priority,
                    status, solutions_checklist, outcome_date, assigned_to,
                    department_id, created_at, updated_at
                FROM crm_tickets
                WHERE created_at >= CURRENT_DATE - INTERVAL '180 days'
                ORDER BY created_at DESC
                LIMIT 5000
            """)
            
            tickets_data = cursor.fetchall()
            logger.info(f"üé´ Retrieved {len(tickets_data):,} tickets from crm_tickets table")
            
            # Process in batches
            batch_size = 500
            for i in range(0, len(tickets_data), batch_size):
                batch = tickets_data[i:i + batch_size]
                
                for ticket_row in batch:
                    try:
                        ticket_data = dict(ticket_row)
                        result = self.ticket_repo.create_or_update(ticket_data)
                        
                        if result is True:
                            self.sync_stats['tickets']['new'] += 1
                        elif result is False:
                            self.sync_stats['tickets']['updated'] += 1
                        else:
                            self.sync_stats['tickets']['skipped'] += 1
                            
                    except Exception as e:
                        logger.error(f"‚ùå Ticket error {ticket_row.get('id', '?')}: {e}")
                        self.sync_stats['tickets']['errors'] += 1
                        continue
                
                db.session.commit()
                logger.info(f"üé´ Ticket batch {i//batch_size + 1} done")
            
            logger.info(f"‚úÖ Tickets sync completed: {self.sync_stats['tickets']}")
            
        except Exception as e:
            logger.error(f"‚ùå Ticket sync failed: {e}")
            raise
    
    def _sync_usage_postgresql(self, cursor):
        """‚úÖ Sync usage from spl_statistics table (ALREADY CORRECT)"""
        try:
            # ‚úÖ This table name was already correct
            cursor.execute("""
                SELECT 
                    id, customer_id, service_id, tariff_id, login,
                    in_bytes, out_bytes, start_date, start_time, 
                    end_date, end_time
                FROM spl_statistics
                WHERE start_date >= CURRENT_DATE - INTERVAL '30 days'
                ORDER BY start_date DESC
                LIMIT 10000
            """)
            
            usage_data = cursor.fetchall()
            logger.info(f"üìä Retrieved {len(usage_data):,} usage records from spl_statistics table")
            
            # Process in batches
            batch_size = 500
            for i in range(0, len(usage_data), batch_size):
                batch = usage_data[i:i + batch_size]
                
                for usage_row in batch:
                    try:
                        usage_record = dict(usage_row)
                        result = self.usage_repo.create_or_update(usage_record)
                        
                        if result is True:
                            self.sync_stats['usage']['new'] += 1
                        elif result is False:
                            self.sync_stats['usage']['updated'] += 1
                        else:
                            self.sync_stats['usage']['skipped'] += 1
                            
                    except Exception as e:
                        logger.error(f"‚ùå Usage error {usage_row.get('id', '?')}: {e}")
                        self.sync_stats['usage']['errors'] += 1
                        continue
                
                db.session.commit()
                logger.info(f"üìä Usage batch {i//batch_size + 1} done")
            
            logger.info(f"‚úÖ Usage sync completed: {self.sync_stats['usage']}")
            
        except Exception as e:
            logger.error(f"‚ùå Usage sync failed: {e}")
            raise
    
    def _sync_via_api(self, sync_options):
        """API sync fallback"""
        logger.info("üåê API sync not implemented - PostgreSQL recommended")
        
        elapsed_time = time.time() - self.sync_stats['start_time']
        return {
            'success': True,
            'message': 'API sync placeholder',
            'stats': self.sync_stats,
            'performance': {
                'connection_method': 'api',
                'sync_duration': elapsed_time,
                'note': 'PostgreSQL direct connection is much faster'
            }
        }
    
    def get_sync_stats(self):
        """Get sync statistics"""
        return self.sync_stats

# Backwards compatibility
CRMService = EnhancedCRMService